{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 24.232633279483036,
  "eval_steps": 500,
  "global_step": 30000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.40387722132471726,
      "grad_norm": 1.5736799240112305,
      "learning_rate": 1.967689822294023e-05,
      "loss": 8.0132,
      "step": 500
    },
    {
      "epoch": 0.8077544426494345,
      "grad_norm": 0.3903377950191498,
      "learning_rate": 1.9353796445880454e-05,
      "loss": 0.3951,
      "step": 1000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.12541449069976807,
      "eval_runtime": 13.1152,
      "eval_samples_per_second": 364.463,
      "eval_steps_per_second": 22.798,
      "step": 1238
    },
    {
      "epoch": 1.2116316639741518,
      "grad_norm": 0.29120492935180664,
      "learning_rate": 1.903069466882068e-05,
      "loss": 0.1897,
      "step": 1500
    },
    {
      "epoch": 1.615508885298869,
      "grad_norm": 0.3016502559185028,
      "learning_rate": 1.8707592891760907e-05,
      "loss": 0.0984,
      "step": 2000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0411812849342823,
      "eval_runtime": 12.6962,
      "eval_samples_per_second": 376.489,
      "eval_steps_per_second": 23.55,
      "step": 2476
    },
    {
      "epoch": 2.0193861066235863,
      "grad_norm": 0.23398371040821075,
      "learning_rate": 1.8384491114701135e-05,
      "loss": 0.0711,
      "step": 2500
    },
    {
      "epoch": 2.4232633279483036,
      "grad_norm": 0.2573159337043762,
      "learning_rate": 1.806138933764136e-05,
      "loss": 0.058,
      "step": 3000
    },
    {
      "epoch": 2.827140549273021,
      "grad_norm": 0.20314699411392212,
      "learning_rate": 1.7738287560581584e-05,
      "loss": 0.0487,
      "step": 3500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.025716321542859077,
      "eval_runtime": 12.4543,
      "eval_samples_per_second": 383.802,
      "eval_steps_per_second": 24.008,
      "step": 3714
    },
    {
      "epoch": 3.231017770597738,
      "grad_norm": 0.1750364452600479,
      "learning_rate": 1.741518578352181e-05,
      "loss": 0.0414,
      "step": 4000
    },
    {
      "epoch": 3.6348949919224554,
      "grad_norm": 0.21996912360191345,
      "learning_rate": 1.7092084006462036e-05,
      "loss": 0.0366,
      "step": 4500
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.015732385218143463,
      "eval_runtime": 14.1538,
      "eval_samples_per_second": 337.718,
      "eval_steps_per_second": 21.125,
      "step": 4952
    },
    {
      "epoch": 4.038772213247173,
      "grad_norm": 0.24617193639278412,
      "learning_rate": 1.6768982229402264e-05,
      "loss": 0.0318,
      "step": 5000
    },
    {
      "epoch": 4.44264943457189,
      "grad_norm": 0.2815904915332794,
      "learning_rate": 1.644588045234249e-05,
      "loss": 0.0277,
      "step": 5500
    },
    {
      "epoch": 4.846526655896607,
      "grad_norm": 0.20262092351913452,
      "learning_rate": 1.6122778675282717e-05,
      "loss": 0.0248,
      "step": 6000
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.009901481680572033,
      "eval_runtime": 12.7055,
      "eval_samples_per_second": 376.215,
      "eval_steps_per_second": 23.533,
      "step": 6190
    },
    {
      "epoch": 5.250403877221324,
      "grad_norm": 0.3100850284099579,
      "learning_rate": 1.579967689822294e-05,
      "loss": 0.021,
      "step": 6500
    },
    {
      "epoch": 5.654281098546042,
      "grad_norm": 0.17977364361286163,
      "learning_rate": 1.547657512116317e-05,
      "loss": 0.0189,
      "step": 7000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.006801421754062176,
      "eval_runtime": 13.5735,
      "eval_samples_per_second": 352.157,
      "eval_steps_per_second": 22.028,
      "step": 7428
    },
    {
      "epoch": 6.058158319870759,
      "grad_norm": 0.10061720758676529,
      "learning_rate": 1.5153473344103394e-05,
      "loss": 0.017,
      "step": 7500
    },
    {
      "epoch": 6.462035541195476,
      "grad_norm": 0.3096373677253723,
      "learning_rate": 1.483037156704362e-05,
      "loss": 0.0151,
      "step": 8000
    },
    {
      "epoch": 6.865912762520194,
      "grad_norm": 0.17579831182956696,
      "learning_rate": 1.4507269789983846e-05,
      "loss": 0.014,
      "step": 8500
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.005110312253236771,
      "eval_runtime": 12.4892,
      "eval_samples_per_second": 382.729,
      "eval_steps_per_second": 23.941,
      "step": 8666
    },
    {
      "epoch": 7.269789983844911,
      "grad_norm": 0.2099732756614685,
      "learning_rate": 1.4184168012924074e-05,
      "loss": 0.0126,
      "step": 9000
    },
    {
      "epoch": 7.673667205169629,
      "grad_norm": 0.22194364666938782,
      "learning_rate": 1.3861066235864299e-05,
      "loss": 0.0113,
      "step": 9500
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.003906907048076391,
      "eval_runtime": 12.5265,
      "eval_samples_per_second": 381.59,
      "eval_steps_per_second": 23.869,
      "step": 9904
    },
    {
      "epoch": 8.077544426494345,
      "grad_norm": 0.16858826577663422,
      "learning_rate": 1.3537964458804525e-05,
      "loss": 0.0105,
      "step": 10000
    },
    {
      "epoch": 8.481421647819063,
      "grad_norm": 0.330400675535202,
      "learning_rate": 1.3214862681744751e-05,
      "loss": 0.01,
      "step": 10500
    },
    {
      "epoch": 8.88529886914378,
      "grad_norm": 0.19757668673992157,
      "learning_rate": 1.2891760904684977e-05,
      "loss": 0.0089,
      "step": 11000
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.003385744756087661,
      "eval_runtime": 12.463,
      "eval_samples_per_second": 383.537,
      "eval_steps_per_second": 23.991,
      "step": 11142
    },
    {
      "epoch": 9.289176090468498,
      "grad_norm": 0.3623034954071045,
      "learning_rate": 1.2568659127625202e-05,
      "loss": 0.0087,
      "step": 11500
    },
    {
      "epoch": 9.693053311793214,
      "grad_norm": 0.17536060512065887,
      "learning_rate": 1.224555735056543e-05,
      "loss": 0.0079,
      "step": 12000
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.0032931019086390734,
      "eval_runtime": 12.4917,
      "eval_samples_per_second": 382.653,
      "eval_steps_per_second": 23.936,
      "step": 12380
    },
    {
      "epoch": 10.096930533117932,
      "grad_norm": 0.18894782662391663,
      "learning_rate": 1.1922455573505656e-05,
      "loss": 0.0075,
      "step": 12500
    },
    {
      "epoch": 10.500807754442649,
      "grad_norm": 0.2151758223772049,
      "learning_rate": 1.1599353796445882e-05,
      "loss": 0.007,
      "step": 13000
    },
    {
      "epoch": 10.904684975767367,
      "grad_norm": 0.28117290139198303,
      "learning_rate": 1.1276252019386107e-05,
      "loss": 0.0068,
      "step": 13500
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.003553685499355197,
      "eval_runtime": 12.6243,
      "eval_samples_per_second": 378.636,
      "eval_steps_per_second": 23.685,
      "step": 13618
    },
    {
      "epoch": 11.308562197092083,
      "grad_norm": 0.13030043244361877,
      "learning_rate": 1.0953150242326333e-05,
      "loss": 0.0063,
      "step": 14000
    },
    {
      "epoch": 11.712439418416801,
      "grad_norm": 0.2252766489982605,
      "learning_rate": 1.0630048465266561e-05,
      "loss": 0.0059,
      "step": 14500
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.003487729001790285,
      "eval_runtime": 12.5067,
      "eval_samples_per_second": 382.196,
      "eval_steps_per_second": 23.907,
      "step": 14856
    },
    {
      "epoch": 12.116316639741518,
      "grad_norm": 0.16634920239448547,
      "learning_rate": 1.0306946688206787e-05,
      "loss": 0.0059,
      "step": 15000
    },
    {
      "epoch": 12.520193861066236,
      "grad_norm": 0.3030807077884674,
      "learning_rate": 9.983844911147012e-06,
      "loss": 0.0054,
      "step": 15500
    },
    {
      "epoch": 12.924071082390952,
      "grad_norm": 0.1988922655582428,
      "learning_rate": 9.660743134087238e-06,
      "loss": 0.0053,
      "step": 16000
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.003883581142872572,
      "eval_runtime": 12.489,
      "eval_samples_per_second": 382.735,
      "eval_steps_per_second": 23.941,
      "step": 16094
    },
    {
      "epoch": 13.32794830371567,
      "grad_norm": 0.12768957018852234,
      "learning_rate": 9.337641357027464e-06,
      "loss": 0.005,
      "step": 16500
    },
    {
      "epoch": 13.731825525040387,
      "grad_norm": 0.23987536132335663,
      "learning_rate": 9.01453957996769e-06,
      "loss": 0.0049,
      "step": 17000
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.0039037903770804405,
      "eval_runtime": 12.472,
      "eval_samples_per_second": 383.258,
      "eval_steps_per_second": 23.974,
      "step": 17332
    },
    {
      "epoch": 14.135702746365105,
      "grad_norm": 0.19394177198410034,
      "learning_rate": 8.691437802907917e-06,
      "loss": 0.0047,
      "step": 17500
    },
    {
      "epoch": 14.539579967689821,
      "grad_norm": 0.37986990809440613,
      "learning_rate": 8.368336025848143e-06,
      "loss": 0.0045,
      "step": 18000
    },
    {
      "epoch": 14.94345718901454,
      "grad_norm": 0.2049127072095871,
      "learning_rate": 8.04523424878837e-06,
      "loss": 0.0044,
      "step": 18500
    },
    {
      "epoch": 15.0,
      "eval_loss": 0.00383810605853796,
      "eval_runtime": 12.4633,
      "eval_samples_per_second": 383.527,
      "eval_steps_per_second": 23.991,
      "step": 18570
    },
    {
      "epoch": 15.347334410339258,
      "grad_norm": 0.24701061844825745,
      "learning_rate": 7.722132471728596e-06,
      "loss": 0.004,
      "step": 19000
    },
    {
      "epoch": 15.751211631663974,
      "grad_norm": 0.2766515016555786,
      "learning_rate": 7.399030694668822e-06,
      "loss": 0.0042,
      "step": 19500
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.003919599112123251,
      "eval_runtime": 12.6545,
      "eval_samples_per_second": 377.732,
      "eval_steps_per_second": 23.628,
      "step": 19808
    },
    {
      "epoch": 16.15508885298869,
      "grad_norm": 0.2766628861427307,
      "learning_rate": 7.075928917609047e-06,
      "loss": 0.0039,
      "step": 20000
    },
    {
      "epoch": 16.55896607431341,
      "grad_norm": 0.11422920227050781,
      "learning_rate": 6.752827140549274e-06,
      "loss": 0.0038,
      "step": 20500
    },
    {
      "epoch": 16.962843295638127,
      "grad_norm": 0.3076309561729431,
      "learning_rate": 6.4297253634895e-06,
      "loss": 0.0038,
      "step": 21000
    },
    {
      "epoch": 17.0,
      "eval_loss": 0.004005303606390953,
      "eval_runtime": 12.5042,
      "eval_samples_per_second": 382.272,
      "eval_steps_per_second": 23.912,
      "step": 21046
    },
    {
      "epoch": 17.366720516962843,
      "grad_norm": 0.29807791113853455,
      "learning_rate": 6.106623586429726e-06,
      "loss": 0.0037,
      "step": 21500
    },
    {
      "epoch": 17.77059773828756,
      "grad_norm": 0.2248014360666275,
      "learning_rate": 5.783521809369952e-06,
      "loss": 0.0036,
      "step": 22000
    },
    {
      "epoch": 18.0,
      "eval_loss": 0.004096689634025097,
      "eval_runtime": 14.0242,
      "eval_samples_per_second": 340.839,
      "eval_steps_per_second": 21.32,
      "step": 22284
    },
    {
      "epoch": 18.17447495961228,
      "grad_norm": 0.1842288374900818,
      "learning_rate": 5.4604200323101785e-06,
      "loss": 0.0035,
      "step": 22500
    },
    {
      "epoch": 18.578352180936996,
      "grad_norm": 0.06329822540283203,
      "learning_rate": 5.137318255250404e-06,
      "loss": 0.0035,
      "step": 23000
    },
    {
      "epoch": 18.982229402261712,
      "grad_norm": 0.21289902925491333,
      "learning_rate": 4.81421647819063e-06,
      "loss": 0.0033,
      "step": 23500
    },
    {
      "epoch": 19.0,
      "eval_loss": 0.004367782734334469,
      "eval_runtime": 13.353,
      "eval_samples_per_second": 357.972,
      "eval_steps_per_second": 22.392,
      "step": 23522
    },
    {
      "epoch": 19.38610662358643,
      "grad_norm": 0.21759018301963806,
      "learning_rate": 4.491114701130856e-06,
      "loss": 0.0034,
      "step": 24000
    },
    {
      "epoch": 19.78998384491115,
      "grad_norm": 0.22471816837787628,
      "learning_rate": 4.168012924071083e-06,
      "loss": 0.0032,
      "step": 24500
    },
    {
      "epoch": 20.0,
      "eval_loss": 0.004366233944892883,
      "eval_runtime": 12.5963,
      "eval_samples_per_second": 379.475,
      "eval_steps_per_second": 23.737,
      "step": 24760
    },
    {
      "epoch": 20.193861066235865,
      "grad_norm": 0.12996111810207367,
      "learning_rate": 3.844911147011309e-06,
      "loss": 0.003,
      "step": 25000
    },
    {
      "epoch": 20.59773828756058,
      "grad_norm": 0.07795819640159607,
      "learning_rate": 3.5218093699515347e-06,
      "loss": 0.0033,
      "step": 25500
    },
    {
      "epoch": 21.0,
      "eval_loss": 0.004349364899098873,
      "eval_runtime": 13.2324,
      "eval_samples_per_second": 361.236,
      "eval_steps_per_second": 22.596,
      "step": 25998
    },
    {
      "epoch": 21.001615508885298,
      "grad_norm": 0.15647734701633453,
      "learning_rate": 3.198707592891761e-06,
      "loss": 0.0032,
      "step": 26000
    },
    {
      "epoch": 21.405492730210018,
      "grad_norm": 0.13693831861019135,
      "learning_rate": 2.875605815831987e-06,
      "loss": 0.003,
      "step": 26500
    },
    {
      "epoch": 21.809369951534734,
      "grad_norm": 0.15246853232383728,
      "learning_rate": 2.5525040387722134e-06,
      "loss": 0.0031,
      "step": 27000
    },
    {
      "epoch": 22.0,
      "eval_loss": 0.004354281350970268,
      "eval_runtime": 12.3505,
      "eval_samples_per_second": 387.03,
      "eval_steps_per_second": 24.21,
      "step": 27236
    },
    {
      "epoch": 22.21324717285945,
      "grad_norm": 0.10667601972818375,
      "learning_rate": 2.2294022617124397e-06,
      "loss": 0.0029,
      "step": 27500
    },
    {
      "epoch": 22.617124394184167,
      "grad_norm": 0.15650805830955505,
      "learning_rate": 1.906300484652666e-06,
      "loss": 0.003,
      "step": 28000
    },
    {
      "epoch": 23.0,
      "eval_loss": 0.004289666656404734,
      "eval_runtime": 12.3336,
      "eval_samples_per_second": 387.559,
      "eval_steps_per_second": 24.243,
      "step": 28474
    },
    {
      "epoch": 23.021001615508887,
      "grad_norm": 0.21090887486934662,
      "learning_rate": 1.583198707592892e-06,
      "loss": 0.003,
      "step": 28500
    },
    {
      "epoch": 23.424878836833603,
      "grad_norm": 0.2574300169944763,
      "learning_rate": 1.2600969305331182e-06,
      "loss": 0.0029,
      "step": 29000
    },
    {
      "epoch": 23.82875605815832,
      "grad_norm": 0.22634394466876984,
      "learning_rate": 9.369951534733441e-07,
      "loss": 0.003,
      "step": 29500
    },
    {
      "epoch": 24.0,
      "eval_loss": 0.004385428968816996,
      "eval_runtime": 12.314,
      "eval_samples_per_second": 388.176,
      "eval_steps_per_second": 24.281,
      "step": 29712
    },
    {
      "epoch": 24.232633279483036,
      "grad_norm": 0.1518854945898056,
      "learning_rate": 6.138933764135703e-07,
      "loss": 0.0028,
      "step": 30000
    }
  ],
  "logging_steps": 500,
  "max_steps": 30950,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 25,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.631602442502144e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
